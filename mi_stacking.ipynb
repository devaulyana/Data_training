{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación verá una función preestablecida, donde:\n",
    "\n",
    "- models - lista de objetos del algoritmo base\n",
    "\n",
    "- meta_alg - meta-algoritmo\n",
    "\n",
    "data_train, target_train, data_test, target_test - atributos de entrenamiento y prueba y variables objetivo\n",
    "\n",
    "- test_size - tamaño de los datos de prueba para la mezcla en el intervalo (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, random_state=None, test_size=None, cv=5):\n",
    "    if test_size is None:\n",
    "        pass\n",
    "    \n",
    "    elif 0 < test_size < 1:\n",
    "        # División en datos de entrenamiento y validación\n",
    "        train_data, val_data, train_targets, val_targets = train_test_split(data_train, targets_train, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # Definición de la matriz meta_mtrx\n",
    "        meta_mtrx = np.zeros((val_data.shape[0], len(models)))\n",
    "        \n",
    "        # Bucle para llenar la matriz meta_mtrx\n",
    "        for i, model in enumerate(models):\n",
    "            # Entrenamiento de un modelo básico sobre datos de entrenamiento\n",
    "            model.fit(train_data, train_targets)\n",
    "            \n",
    "            # Llenar una columna de matriz con predicciones basadas en datos de validación\n",
    "            meta_mtrx[:, i] = model.predict(val_data)\n",
    "        \n",
    "        # Metaalgoritmo de entrenamiento en la matriz meta_mtrx\n",
    "        meta_alg.fit(meta_mtrx, val_targets)\n",
    "        \n",
    "        # Definición de la matriz meta_mtrx_test\n",
    "        meta_mtrx_test = np.zeros((data_test.shape[0], len(models)))\n",
    "        \n",
    "        # Bucle para llenar la matriz meta_mtrx_test\n",
    "        for i, model in enumerate(models):\n",
    "            # Llenar la columna de la matriz con predicciones sobre los datos de prueba\n",
    "            meta_mtrx_test[:, i] = model.predict(data_test)\n",
    "        \n",
    "        # Predicciones de metaalgoritmo para valores meta_mtrx_test\n",
    "        meta_predictions = meta_alg.predict(meta_mtrx_test)\n",
    "        \n",
    "        # Comprobando objetivos_prueba y generando precisión_puntuación\n",
    "        if targets_test is not None:\n",
    "            accuracy = accuracy_score(targets_test, meta_predictions)\n",
    "            print(f\"Accuracy on Test Data: {accuracy}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "# usaremos el conjunto de datos de Iris como ejemplo\n",
    "iris = load_iris()\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definición de algoritmos básicos\n",
    "base_models = [\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=50, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    SVC(random_state=17)\n",
    "\n",
    "]\n",
    "\n",
    "# Definición de algoritmos básicos\n",
    "meta_model = LogisticRegression(random_state=42, multi_class='ovr')\n",
    "\n",
    "# Probando la función de apuesta en tres variantes diferentes\n",
    "try:\n",
    "    # Opción 1: lanzar una excepción\n",
    "    stacking(base_models, meta_model, data_train, targets_train, data_test, targets_test=None, test_size=None, cv=5)\n",
    "except ValueError as e:\n",
    "    print(f\"Opción 1: {e}\")\n",
    "\n",
    "# Opción 2: configurar test_size=0.3\n",
    "stacking(base_models, meta_model, data_train, targets_train, data_test, targets_test, test_size=0.3, cv=5)\n",
    "\n",
    "# Opción 3: test_size=Ninguno\n",
    "stacking(base_models, meta_model, data_train, targets_train, data_test, targets_test, test_size=None, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
